{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNd6AzsAOp403HM0Go9hlCf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shinyasyokukai/AIC/blob/main/AIC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 注意\n",
        "このノートは現状  \n",
        "https://nbviewer.org/github/genkuroki/Statistics/blob/master/KL%20information%20and%20descriptive%20statistics.ipynb  \n",
        "と  \n",
        "https://genkuroki.github.io/documents/20160616KullbackLeibler.pdf  \n",
        "の丸パクリ (というか超絶劣化版) である。  \n",
        "あとマークダウンの練習のために無駄にいっぱい数式書いてます。  \n",
        "最終的には AIC について基本的なことをまとめて具体的な例で実験したい。  \n",
        "public にしたくなかったけど colab から push するためにしょうがなかった。  \n",
        "private なリポジトリだと共有するのめんどいし。  \n",
        "恥ずかしいので発表終わったら速やかに private にします。"
      ],
      "metadata": {
        "id": "GKJGaV8nUvHh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# スターリングの公式\n",
        "$$\n",
        "\\begin{align}\n",
        "n! &= n^ne^{-n}\\sqrt{2\\pi n}(1 + o(1)) \\quad (n\\rightarrow∞)\\\\\n",
        "⇔\\ln n! &= n\\ln n - n + \\frac{1}{2}\\ln n + \\ln\\sqrt{2\\pi} + o(1) \\quad (n\\rightarrow∞)\n",
        "\\end{align}\n",
        "$$\n",
        "特に\n",
        "$$\n",
        "\\ln n! = n\\ln n - n + O(\\ln n)\n",
        "$$\n",
        "となる。  \n",
        "最後の評価は荒いが、今回はこれで十分。  \n",
        "また、\n",
        "$$\n",
        "\\begin{align}\n",
        "\\sum_{x = 1}^n\\ln x &= \\ln n!\\\\\n",
        "\\int_1^n\\ln x\\mathrm{d}x &= n\\ln n - n + 1\n",
        "\\end{align}\n",
        "$$\n",
        "より、最後の評価は対数関数の積分を和で近似した際の誤差のオーダーが $\\ln n$ であることを示している。\n",
        "# KL 情報量\n",
        "確率分布 $p$ の確率分布 $q$ に対する KL 情報量 $D(q||p)$ を\n",
        "$$\n",
        "D(q||p) := ∫q(x)\\ln{\\frac{q(x)}{p(x)}}\\mathrm{d}x\n",
        "$$\n",
        "で定義する。\n",
        "$$\n",
        "\\begin{align}\n",
        "D(q||p) &= \\left(-∫q(x)\\ln p(x)\\mathrm{d}x\\right) -\\left(-∫q(x)\\ln q(x)\\mathrm{d}x\\right)\\\\\n",
        "&= G(q||p) - S(q)\n",
        "\\end{align}\n",
        "$$\n",
        "と書ける。ここに、\n",
        "$$\n",
        "\\begin{align}\n",
        "G(q||p) &:= -∫q(x)\\ln p(x)\\mathrm{d}x\\\\\n",
        "S(q) &:= -∫q(x)\\ln q(x)\\mathrm{d}x \n",
        "\\end{align}\n",
        "$$\n",
        "である。$G(q||p)$ を $p$ の $q$ に対する交差エントロピー、もしくは汎化誤差と呼び、$S(q)$ をシャノンエントロピー$^{[\\mathrm{注}1]}$と呼ぶ。  \n",
        "\n",
        "シャノンエントロピー $S(q)$ は \" $q$ に従って発生する記号列を (適切に) 符号化した際の平均符号長\" 、交差エントロピー $G(q||p)$ は \" $q$ に従って発生する記号列を $p$ に従うと考えて記号化した時の平均符号長\" と解釈される。  \n",
        "よって KL 情報量 $D(q||p)$ は \"実際には $q$ に従って発生する記号列を $p$ に従うとして符号化した際の平均符号長のロス\" と解釈できる (ただし $p$, $q$ が離散的な場合に限る)。  \n",
        "また、$-\\ln p(x)$ が \" $p$ に従う確率変数 $X$ について、$X = x$ と知らされたときに受け取る情報量\" であったことを思い出そう。改めて\n",
        "$$\n",
        "D(q||p) = -∫q(x)[\\{-\\ln q(x)\\} - \\{-\\ln p(x)\\}]\\mathrm{d}x\n",
        "$$\n",
        "と書き、$p$ を事前分布、$q$ を事後分布と見なせば、$D(q||p)$ は \"事前分布 $p$ を 事後分布 $q$ に更新することで、$X$ の値を知って受け取る情報量が平均的にどれだけ減ったか\" を表すとも考えられる。  \n",
        "これらの解釈でも $D(q||p)$ が $q$ と $p$ の違いを測るものであることはなんとなく了解されると思うが、 $q$ を $p$ で近似するという立場からより直接的な意味付けを以下に与える。\n",
        "# Sanov の定理による KL 情報量の意味付け\n",
        "### Sanov の定理$^{[\\mathrm{注}2]}$\n",
        "$p$, $q$を確率分布とし、$X_1,X_2,…$ が $p$ に従う独立同分布な確率変数列であるとする。このとき \"$X_1,…,X_n$ が $q$ に従うように見える確率\" は\n",
        "$$\n",
        "\\exp(-nD(q||p) + o(n))\n",
        "$$\n",
        "となる。つまり、KL 情報量 $D(q||p)$ は $p$ に従う乱数列が $q$ に従うように見える確率の対数が減衰する速さである。\n",
        "### 証明\n",
        "一般の場合の証明は大変 (というか僕も知らない) なので $p$, $q$ ともに有限台の離散確率分布とする。  \n",
        "すなわち、有限集合 $\\{1,…,r\\}$ 上の非負値関数で\n",
        "$$\n",
        "\\begin{align}\n",
        "\\sum_{i=1}^{r}p_i &= 1,\\\\\n",
        "\\sum_{i=1}^{r}q_i &= 1 \n",
        "\\end{align}\n",
        "$$\n",
        "を満たすものを考える。  \n",
        "また簡単のため、任意の $i$ について $p_i,q_i>0$ とする。  \n",
        "$(X_n)_{n=1}^∞$ を $p$ に従う独立同分布な確率変数列とする。  \n",
        "$n$ を正整数とする。$\\sum_{i = 1}^rk_i=n$ を満たす非負整数列 $(k_i)_{i=1}^r$ を与える。\n",
        "$$\n",
        "k_i=\\#\\{m≤n|X_m=i\\} \\quad (i = 1,…,r)\n",
        "$$ \n",
        "となる (すなわち値 $i$ がちょうど $k_i$ 回観測される) 確率は\n",
        "$$\n",
        "\\frac{n!}{k_1!…k_r!}p_1^{k_1}…p_r^{k_r}\n",
        "$$\n",
        "となる。  \n",
        "ここで、$k_i = nq_i(1 + O(\\frac{\\ln{n}}{n})) = nq_i + O(\\ln n)$ であると仮定する。  \n",
        "このとき特に $\\frac{k_i}{n}→q_i\\quad(n→∞)$ となる (つまり $(X_n)_{n=1}^∞$ がまるで $q$ に従うように見える)。  \n",
        "スターリングの公式より\n",
        "$$\n",
        "\\begin{align}\n",
        "  \\ln n! &= n\\ln n - n + O(\\ln n)\\\\\n",
        "  \\ln k_i! &= k_i\\ln k_i - k_i + O(\\ln k_i)\\\\\n",
        "  &=k_i\\ln k_i - k_i + O(\\ln n)\\\\\n",
        "  \\ln p_i^{k_i} &= k_i\\ln p_i\n",
        "\\end{align}\n",
        "$$\n",
        "また、仮定より\n",
        "$$\n",
        "\\begin{align}\n",
        "  \\ln \\frac{k_i}{n} &= \\ln q_i + \\ln \\left(1 + O\\left(\\frac{\\ln{n}}{n}\\right)\\right)\\\\\n",
        "  &= \\ln q_i + O\\left(\\frac{\\ln{n}}{n}\\right)\n",
        "\\end{align}\n",
        "$$\n",
        "ゆえに、仮定と合わせて\n",
        "$$\n",
        "\\begin{align}\n",
        "  \\ln\\frac{n!}{k_1!…k_r!}p_1^{k_1}…p_r^{k_r} &= n\\ln n - k_1\\ln k_1 - … - k_r\\ln k_r + k_1\\ln p_1 + … + k_r\\ln p_r + O(\\ln n)\\\\\n",
        "  &= - k_1\\left(\\ln\\frac{k_1}{n} - \\ln p_1\\right) - … - k_r\\left(\\ln\\frac{k_r}{n} - \\ln p_r\\right) + O(\\ln n)\\\\\n",
        "  &= - k_1\\left(\\ln q_1 - \\ln p_1\\right) - … - k_r\\left(\\ln q_r - \\ln p_r\\right) + O(\\ln n)\\\\\n",
        "  &= - nq_1\\ln\\frac{q_1}{p_1} - … - nq_r\\ln\\frac{q_r}{p_r} + O(\\ln n)\\\\\n",
        "  &=-nD(q||p) + o(n)\n",
        "\\end{align}\n",
        "$$\n",
        "従って、\"$X_1,…,X_n$ が $q$ に従うように見える確率\" は\n",
        "$$\n",
        "\\exp(-nD(q||p) + o(n))\n",
        "$$\n",
        "となる (証明終)。\n",
        "### 注意\n",
        "通常 $0\\ln 0=0$ と約束するので、$q_i=0$ となる $i$ があっても上の評価は問題なく成立する。  \n",
        "しかし $q_i>0$ かつ $p_i=0$ なる $i$ があると $D(q||p) = ∞$ となり、上の評価は破綻する。  \n",
        "これは、$i$ の目が絶対出ないサイコロを $i$ の目が出るサイコロでたまたまシミュレートすることはできても、$i$ の目が出るサイコロを $i$ の目が出ないサイコロでシミュレートすることはできないことに対応する...のだと思う。\n",
        "# KL 情報量の諸性質\n",
        "KL 情報量の重要な性質として非負値性と非退化性を示す。\n",
        "$$\n",
        "\\begin{align}\n",
        "  &(\\mathrm{非負値性})\\quad D(q||p) ≥ 0\\\\\n",
        "  &(\\mathrm{非退化性})\\quad D(q||p)= 0 ⇔ p = q\n",
        "\\end{align}\n",
        "$$\n",
        "### 証明\n",
        "$$\n",
        "\\begin{align}\n",
        "  D(q||p) &= ∫q(x)\\ln{\\frac{q(x)}{p(x)}}\\mathrm{d}x\\\\\n",
        "          &= ∫q(x)\\left(-\\ln{\\frac{p(x)}{q(x)}}\\right)\\mathrm{d}x\\\\\n",
        "          &≥ -\\ln\\left(∫q(x){\\frac{p(x)}{q(x)}}\\mathrm{d}x\\right)\\\\\n",
        "          &= -\\ln\\left(∫p(x)\\mathrm{d}x\\right)\\\\\n",
        "          &= -\\ln 1\\\\\n",
        "          &= 0\n",
        "\\end{align}\n",
        "$$\n",
        "ここで、3 行目の変形には「 $t \\mapsto - \\ln t$ が下に凸であること」と、Jensen の不等式を用いた。  \n",
        "また、$t \\mapsto - \\ln t$ は狭義凸であるので、等号成立条件は\n",
        "$$\n",
        "\\frac{p(x)}{q(x)} ≡ \\mathrm{const}.\n",
        "$$\n",
        "となるが、$∫p(x)\\mathrm{d}x = ∫q(x)\\mathrm{d}x = 1$ からこれは $p = q$ と同値である (証明終)。   \n",
        "以上の結果より、KL 情報量 $D(q||p)$ は確率分布 $p$, $q$ 間の距離のようなものである。  \n",
        "ただし、対称性 ($D(q||p) = D(p||q)$) や三角不等式 ($D(p||q) \\leq D(p||r) + D(r||q)$) は一般には成り立たない。  \n",
        "適切な定式化の元で三平方の定理が成立するため、どちらかといえば距離の二乗に相当する量である$^{[\\mathrm{注}3]}$。\n",
        "# 例\n",
        "### 1. 正規分布\n",
        "$$\n",
        "\\begin{align}  \n",
        "  q(x) &= \\frac{1}{\\sqrt{2\\pi\\sigma_0^2}}\\exp\\left\\{-\\frac{(x-\\mu_0)^2}{2\\sigma_0^2}\\right\\}\\\\\n",
        "  p(x) &= \\frac{1}{\\sqrt{2\\pi\\sigma_1^2}}\\exp\\left\\{-\\frac{(x-\\mu_1)^2}{2\\sigma_1^2}\\right\\}\n",
        "\\end{align}\n",
        "$$\n",
        "として、KL 情報量 $D(q||p)$ を求める。\n",
        "$$\n",
        "\\begin{align}  \n",
        "  D(q||p) &= ∫q(x)\\ln{\\frac{q(x)}{p(x)}}\\mathrm{d}x\\\\\n",
        "          &= ∫q(x)\\ln q(x)\\mathrm{d}x -∫q(x)\\ln p(x)\\mathrm{d}x\\\\\n",
        "\\end{align}\n",
        "$$\n",
        "ここで、\n",
        "$$\n",
        "\\begin{align}  \n",
        "  ∫q(x)\\ln p(x)\\mathrm{d}x &= ∫q(x) \\ln \\frac{1}{\\sqrt{2\\pi\\sigma_1^2}} \\mathrm{d}x - ∫q(x)\\frac{(x-\\mu_1)^2}{2\\sigma_1^2}\\mathrm{d}x\\\\\n",
        "          &= -\\frac{1}{2}\\ln 2\\pi\\sigma_1^2 - \\frac{1}{2\\sigma_1^2}\\left\\{∫q(x)(x-\\mu_0)^2 \\mathrm{d}x + 2(\\mu_0-\\mu_1)∫q(x)(x-\\mu_0)\\mathrm{d}x + ∫q(x)(\\mu_0-\\mu_1)^2\\mathrm{d}x \\right\\}\\\\\n",
        "          &= -\\frac{1}{2}\\ln 2\\pi\\sigma_1^2 - \\frac{\\sigma_0^2+(\\mu_0-\\mu_1)^2}{2\\sigma_1^2}\n",
        "\\end{align}\n",
        "$$\n",
        "より、\n",
        "$$\n",
        "\\begin{align}  \n",
        "  D(q||p) &= \\left\\{-\\frac{1}{2}\\ln 2\\pi\\sigma_0^2 - \\frac{\\sigma_0^2+(\\mu_0-\\mu_0)^2}{2\\sigma_0^2}\\right\\}-\\left\\{-\\frac{1}{2}\\ln 2\\pi\\sigma_1^2 - \\frac{\\sigma_0^2+(\\mu_0-\\mu_1)^2}{2\\sigma_1^2}\\right\\}\\\\\n",
        "          &= \\frac{1}{2} \\left\\{\\ln\\frac{\\sigma_1^2}{\\sigma_0^2} + \\frac{\\sigma_0^2+(\\mu_0-\\mu_1)^2}{\\sigma_1^2} -1 \\right\\}\\\\\n",
        "\\end{align}\n",
        "$$\n",
        "となる。\n",
        "### 2. ベルヌーイ分布\n",
        "$$\n",
        "\\begin{align}  \n",
        "  q(x=0) &= q\\\\\n",
        "  q(x=1) &= 1-q\\\\\n",
        "  p(x=0) &= p\\\\\n",
        "  p(x=1) &= 1-p\\\\\n",
        "\\end{align}\n",
        "$$\n",
        "とすると、KL 情報量 $D(q||p)$ は\n",
        "$$ \n",
        "  D(q||p) = q\\ln \\frac{q}{p} + (1-q)\\ln \\frac{1-q}{1-p}\n",
        "$$\n",
        "となる。"
      ],
      "metadata": {
        "id": "9_hd8FYCG851"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TeZoUwJ6d14k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 注釈\n",
        "### 注1:\n",
        "KL 情報量 $D(q||p)$ は離散・連続にかかわらず一般の確率測度 $p$, $q$ に対し、ラドン＝ニコディム微分を用いて\n",
        "$$\n",
        "D(q||p) = ∫\\left(\\ln \\frac{\\mathrm{d}q}{\\mathrm{d}p}\\right)\\mathrm{d}q\n",
        "$$\n",
        "と定義できる。これはシャノンエントロピーが\n",
        "$$\n",
        "\\begin{align}\n",
        "S_{\\mathrm{discrete}}(q) &:= -\\sum_x q(x)\\ln q(x)\\\\\n",
        "S_{\\mathrm{continuous}}(q) &:= -∫q(x)\\ln q(x)\\mathrm{d}x \n",
        "\\end{align}\n",
        "$$\n",
        "と離散・連続の場合で別々に定義されたのとは対照的である。  \n",
        "また、$q$ が $\\{1,…,r\\}$ にしか値を持たないなら、\n",
        "$$\n",
        "S_{\\mathrm{discrete}}(q) = \\ln r - D(q||p_{\\mathrm{uniform}})\n",
        "$$\n",
        "と書ける。ここに、$p_{\\mathrm{uniform}}$ は $\\{1,…,r\\}$ 上の一様分布である。  \n",
        "連続の場合も同様にシャノンエントロピーを一様分布との KL 情報量で表すことができる (ただし、$\\mathbf{Z}$ や $\\mathbf{R}$ 上の一様分布は存在しないため、この説明はいささかずるい)。  \n",
        "ゆえに KL 情報量はシャノンエントロピーよりも基本的な量であると考えられる。\n",
        "### 注2:\n",
        "Sanov の定理は大偏差原理と呼ばれるものの一種である。  \n",
        "大偏差原理とは以下のような\n",
        "\n",
        "### 注3:\n",
        "確率分布族をなめらかな図形 (統計多様体) とみなし、その上の幾何学を考える分野を情報幾何という。  \n",
        "そこでは 1 つの確率分布は図形上の 1 点とみなされ、KL 情報量は 2 点間の距離の二乗に相当する。  \n",
        "また、同じ点における接ベクトル間の内積がフィッシャー情報行列というもので与えられる。  \n",
        "内積があれば角度が考えられ、直角三角形を考えることで KL 情報量についての三平方の定理が得られる。  \n",
        "さらに、フィッシャー情報行列は KL 情報量のヘッシアンに相当する (テイラー展開における 2 次の項になる) こともわかる。"
      ],
      "metadata": {
        "id": "8w4wasufSUTx"
      }
    }
  ]
}